# WATER-QUALITY-PREDICTION-USING-MACHINE-LEARNING-MODELS
A machine learning project that predicts water potability using various classification algorithms to ensure safe drinking water quality.
## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Dataset](#dataset)
- [Machine Learning Models](#machine-learning-models)
- [Installation](#installation)
- [Usage](#usage)
- [Results](#results)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [Authors](#authors)
- [License](#license)

## ğŸ” Overview

Access to safe drinking water is a fundamental human right. This project uses machine learning to classify water samples as safe or unsafe for consumption based on key water quality indicators. We evaluated **6 different machine learning models** to predict water potability with varying accuracy rates.

**Key Highlights:**
- ğŸ¯ Best Model: Support Vector Machine (SVM) with **66.08% accuracy**
- ğŸ“Š Dataset: 3,276 records with 10 water quality features
- ğŸ”¬ Models Tested: 6 classification algorithms
- ğŸ“ˆ Train/Test Split: 66% / 33%

## ğŸ“Š Dataset

The dataset contains **3,276 water samples** with the following features:

| Feature | Description |
|---------|-------------|
| **pH** | pH level of water |
| **Hardness** | Water hardness (mg/L) |
| **Solids** | Total dissolved solids (ppm) |
| **Chloramines** | Chloramines concentration (ppm) |
| **Sulfate** | Sulfate concentration (mg/L) |
| **Conductivity** | Electrical conductivity (Î¼S/cm) |
| **Organic Carbon** | Organic carbon content (ppm) |
| **Trihalomethanes** | Trihalomethanes concentration (Î¼g/L) |
| **Turbidity** | Water turbidity (NTU) |
| **Potability** | Target variable (0 = Not Potable, 1 = Potable) |

## ğŸ¤– Machine Learning Models

We implemented and compared the following algorithms:

### 1. **Logistic Regression**
- Binary classification using sigmoid function
- Accuracy: **60.11%**

### 2. **Decision Tree**
- Tree-based hierarchical classification
- Accuracy: **62.62%**

### 3. **K-Nearest Neighbors (KNN)**
- Instance-based learning algorithm
- Accuracy: **57.56%** (Lowest)

### 4. **Gaussian NaÃ¯ve Bayes**
- Probabilistic classifier based on Bayes' theorem
- Accuracy: **61.39%**

### 5. **Support Vector Machine (SVM)** â­
- Optimal hyperplane classification
- Accuracy: **66.08%** (Highest)

### 6. **Random Forest**
- Ensemble learning with multiple decision trees
- Accuracy: **62.84%**

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Setup

1. Clone the repository
```bash
git clone https://github.com/yourusername/water-quality-analysis.git
cd water-quality-analysis
```

2. Create a virtual environment (optional but recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install required packages
```bash
pip install -r requirements.txt
```

### Required Libraries

```
numpy
pandas
scikit-learn
matplotlib
seaborn
jupyter
```

## ğŸ’» Usage

### Running the Analysis

1. **Jupyter Notebook**
```bash
jupyter notebook
```
Open `water_quality_analysis.ipynb` and run all cells.

2. **Python Script**
```bash
python train_models.py
```

### Basic Example

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

# Load dataset
data = pd.read_csv('water_quality.csv')

# Prepare features and target
X = data.drop('Potability', axis=1)
y = data['Potability']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train SVM model
svm_model = SVC(kernel='rbf')
svm_model.fit(X_train_scaled, y_train)

# Evaluate
accuracy = svm_model.score(X_test_scaled, y_test)
print(f"Accuracy: {accuracy * 100:.2f}%")
```

## ğŸ“ˆ Results

### Model Performance Comparison

| Model | Accuracy | Rank |
|-------|----------|------|
| **Support Vector Machine (SVM)** | 66.08% | ğŸ¥‡ |
| **Random Forest** | 62.84% | ğŸ¥ˆ |
| **Decision Tree** | 62.62% | ğŸ¥‰ |
| **Gaussian NaÃ¯ve Bayes** | 61.39% | 4 |
| **Logistic Regression** | 60.11% | 5 |
| **K-Nearest Neighbors** | 57.56% | 6 |

### Key Findings

- âœ… **SVM performed best** with 66.08% accuracy, effectively separating potable and non-potable water samples
- ğŸ“Š Feature importance analysis revealed critical water quality indicators
- âš ï¸ Class imbalance in the dataset affected model performance
- ğŸ”„ Hyperparameter tuning and cross-validation improved model robustness

### Confusion Matrix Analysis

The models showed:
- High **True Positives** for the majority class
- Elevated **False Negatives** due to class imbalance
- Room for improvement in minority class detection

## ğŸ“ Project Structure

```
water-quality-analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ water_quality.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ water_quality_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ train_models.py
â”‚   â””â”€â”€ evaluate_models.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â”œâ”€â”€ accuracy_comparison.png
â”‚   â””â”€â”€ feature_importance.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ‘¥ Author

- **Ubaid Ullah**
 
**Course:** Machine Learning Lab (COMP-240L)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


â­ If you found this project helpful, please consider giving it a star!

**Made with â¤ï¸ for safe drinking water**
